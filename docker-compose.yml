version: '3.4' #docker version 3.4
services:
  fastapi:
    build: #building the image using Dockerfile
      context: .
      dockerfile: ./Dockerfile
    container_name: fastapi
    volumes: #changes in current directory will affect app directory in container
      - .:/code/app
      - ./vector_documents:/code/vector_documents
    environment: #environmental variables
      NODE_ENV: development
      DATABASE_URL: mysql://root:S3cret@db:3306/pdf
    ports: #expose port 3000 for outside use
      - 3000:80
  #if no exposed ports, anything outside of the docker network can't access it
  llama:
    build: #build ollama image
      context: .
      dockerfile: ./Dockerfile.ollama
    container_name: ollama
    #entrypoint is shell script, this is main process
    entrypoint: /entrypoint.sh
    #cache the ollama model for faster download time
    ports:
      - 11434:11434
    volumes:
      - ./ollama_cache:/root/.ollama 
  stream:
    build:
      context: .
      dockerfile: ./Dockerfile.ui
    container_name: stream
    volumes:
      - ./ui.py:/code/ui.py
    ports:
      - 8501:8501
  open-webui:
     image: ghcr.io/open-webui/open-webui:main
     container_name: open-webui
     ports:
       - 8282:8080
     volumes:
       - open-webui:/app/backend/data
     environment:
        - OLLAMA_BASE_URL=http://llama:11434
        - HOST = llama
     restart: unless-stopped
volumes:
  open-webui:
